---
title: "Statistical Learning, Homework-01"
author: "Barba Paolo, Candi Matteo, Costantini Silvia, Vestini Maria Vittoria"
date: '2023-05-10'



output: 
  html_document:
    code_folding: hide
    theme: 
      color-contrast-warnings: false
      bg: "#2B3E50"
      fg: "#B8BCC2"
      primary: "#EA80FC"
      secondary: "#00DAC6"
      base_font:
      google: Prompt
      heading_font:
        google: Proza Libre
---

```{r setup, include=FALSE}
if (requireNamespace("thematic")) 
  thematic::thematic_rmd(font = "auto")
```

```{r package, message=FALSE}

rm(list = ls())

# Set reproducibility -----------------------------------------------------
seed <- 1234
set.seed(seed) 

# Libraries and Data ---------------------------------------------------------------

pkt <- c('glmnet', 'NMOF', 'parallel', 'snow', 'ggplot2', 'reshape2', 'gridExtra')
invisible(lapply(pkt, require, character.only = TRUE))

```

## Purpose & Statistical tools used

[TODO]

## Be linear in transformed feature space

[TODO]

## Implementation of the truncated power basis

[TODO] Spiegare perchÃ¨ usiamo solo le potenze dispari

```{r power_function}

# Function used to compute the feature matrix
power_functions <- function(d, q, knots, x){
  X <- matrix(NA, length(x), d+q+1)  # Pre-set the feature matrix 
  for( i in 1:length(x)){            # Loop over the data-points
    
    for( j in 1:(d+q+1) ){           # Loop over the basis used
      
      if ( j <= d+1 ){               # Check if the index belong to the firsts (d+1) indices  
        X[i,j] <- x[i]^(j-1)         # Compute the powers
      }
      
      else                           # The index do not belong to the firsts (d+1) indices  
        if((x[i] - knots[j-(d+1)])^d > 0){      # Check if the power of the difference between the data-point and the knot is positive
          X[i,j] <- (x[i] - knots[j-(d+1)])^d   # Compute the power of the difference
        }
      else                           # the power is not positive
         X[i,j] <- 0                 # Set the value to 0
    }   
  }
  return(X)                         # Return the feature matrix
}

```

[TODO Matteo]

```{r plot truncated power function, fig.showtext = TRUE, fig.height = 7, fig.width = 12, fig.align = "center"}

plot_func <- function(d, q){
  knots <- seq(0, 1, length.out = q+2)[2 : (q+1)]
  df <- data.frame(power_functions(d, q, knots, xx))
  n_col <- ncol(df)
  legend_labels <- c()
  for (i in 1:n_col) legend_labels <- c(legend_labels, paste0('g', i, '(x)'))
  colnames(df) <- legend_labels
  df <- cbind('xx' = xx, df)
  df <- melt(df,  id.vars = 'xx')
  
  graph <- ggplot(data=df, aes(x = xx, y = value, color = variable)) + 
    geom_line(linewidth = 1) + 
    ggtitle(paste0('Plot with d = ', d, ' and  q = ', q)) + 
    xlab('x') +
    ylab('y') +
    theme_light() + 
    theme(panel.grid = element_blank(),
          panel.background = element_rect(fill = NA),
          
          title = element_text(colour = "white"),
          
          plot.background = element_rect(fill = NA, colour = "#2B3E50"), 
          plot.title = element_text(size=16),
          
          axis.line = element_line(color = "white"),
          axis.text = element_text(color = "white", size = 10),
          axis.title.y = element_text(angle = 0, vjust = 0.5),
          
          legend.title = element_blank(),
          legend.text = element_text(size = 10, color = 'white'),
          legend.key = element_rect(color = NA, fill = NA),
          legend.key.size = unit(0.6, "cm"),
          legend.background = element_rect(fill = NA))
      
  return(graph)
}

xx <- seq(0, 1, length.out = 1000)

p1 <- plot_func(1, 3)
p2 <- plot_func(3, 3)
p3 <- plot_func(1, 10)
p4 <- plot_func(3, 10)

grid.arrange(p1, p2, p3, p4, ncol=2)

```

## ChatGPT - Power function
[TODOMatteo]  Vogliamo che i codici in questa sezione non vengano nascosti, come si fa? Se non riesci, basta un modo per mostrarlo come html (carino)

Request:

" Can you implement a function in r to compute the truncated power basis, with parameters d, q, knots. Where $g_i=x^{i-1}$ if $i\le(d+1)$ else $g_{d+1+j} = \max((x-knots[j])^d, 0)$ for $j \in [1,q]$? "

Response:

" Certainly! Here's a function in R that computes the truncated power basis you described:

```{r, class.source = "fold-show"}

truncated_power_basis <- function(x, d, q, knots) {
  # Compute the first d+1 basis functions
  basis <- matrix(0, nrow = length(x), ncol = d+1)
  basis[,1] <- 1
  for (i in 2:(d+1)) {
    basis[,i] <- x^(i-1)
  }
  
  # Compute the remaining basis functions using knots
  for (j in 1:q) {
    basis[,d+1+j] <- pmax((x - knots[j])^d, 0)
  }
  
  return(basis)
}
```


This function takes as input the vector x, the integer d, the integer q, and the vector knots. It returns a matrix with length(x) rows and d+1+q columns, where each column represents a basis function.

To use this function, simply call truncated_power_basis(x, d, q, knots) with your desired inputs. For example, if you want to compute the truncated power basis with d=3, q=2, and knots=c(0.5, 1.5) for the vector x=c(0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4), you would call truncated_power_basis(x, 3, 2, c(0.5, 1.5)). "

Let's try it!

```{r GPtest, error=TRUE, class.source = "fold-show"}

d <- 1
q <- 3
knots <- seq(0, 1, length.out=q)
x <- seq(0, 1, length.out=1000)

M <- truncated_power_basis(x, d, q, knots)

```

Ops! Looks like the ChatBot response doesn't work.

# TODO Finisci di scrivere evaluation

## Dataset

[TODO]

```{r dataset}

test_set_vero <- read.csv("test.csv")
train_set <- read.csv("train.csv")

```

## Pre-processed

[TODO]

```{r data - preproocessing 1 , warning= FALSE , echo = FALSE , fig.width = 10}

# Outlier Detection
quant <- range(quantile(train_set$y, c(0.25, 0.75)))
Lower <- quant[1] - 1.5*(diff(quant))
Upper <- quant[2] + 1.5*(diff(quant))

train_set <- train_set[(train_set$y > Lower)& (train_set$y < Upper),]

```

## Vanilla Cross Validation

```{r functions VCV}

# Function to estimate the weights
compute_weights <- function(knots , dataset){
  # Number of knots
  n <- length(knots)
  # Add the bounds 
  knots <- c(0, knots, 1)
   # Define the matrix
  xx <- rep(NA, length(dataset$x))
  
   # For each interval bounded by the knots
  for(i in 1:(n+1)){
    # Check if there are at least 2 data points inside the interval
    if(sum(dataset$x >= knots[i] & dataset$x <= knots[i+1])>1){    
      # Compute the conditional variance 
      v  <- var(dataset$y[(dataset$x >= knots[i]) & (dataset$x <= knots[i+1])]) 
      # Set the weight of the data points equal to the inverse of the variance
      xx[dataset$x >= knots[i] & dataset$x <= knots[i+1]] <- 1 / v              
    } 
    # If there is only one data point
    else if(sum(dataset$x >= knots[i] & dataset$x <= knots[i+1]) == 1){  
      # Since we can't compute the variance of a single data point then we use the previously computed variance
      xx[dataset$x >= knots[i] & dataset$x <= knots[i+1]] <- 1/v
    }
  }
  
  return(xx)
}
if(sum(NULL)){
  print('cciao')
}

# Function used for the cross validation
cross_val_func <- function(x){
  d <- x[1]
  q <- x[2]
  k <- x[3]
  a <- x[4]
  l <- x[5] 
  p <- x[6]
  
  # size of the fold
  l_folds <- nrow(train_set) / k 
  score <- rep(NA, k)
  for ( i in 1:k){
    idx <- ((i-1)*l_folds+1): (i*l_folds)
    cv_test <- train_set[idx,]
    cv_train <- train_set[-idx,]
    
    
    knots <- seq(1/q, p, length.out=q)
    
    M_cv_train <- power_functions(d = d, q = q, knots = knots, x = cv_train$x)
    # M_cv_train <- data.frame(M_cv_train , target = cv_train$y)
    
    M_cv_test <-  power_functions(d = d, q = q, knots = knots, x = cv_test$x)

    hat_weights <- compute_weights(knots = knots , cv_train)
    
    cv_model <- glmnet(M_cv_train, 
                       cv_train$y,
                       family = "gaussian", 
                       alpha=a, 
                       lambda=l,
                       weights = hat_weights)
    
    cv_predictions <- predict(cv_model, M_cv_test)
    
    score[i] <- sqrt(mean((cv_test$y-cv_predictions)^2))
    
  }
  return(mean(score))
}
```